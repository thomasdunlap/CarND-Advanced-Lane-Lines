{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "* The goals / steps of this project are the following:\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                 # Matrix math\n",
    "import cv2                         # OpenCV for image processing\n",
    "import glob                        # Filename pattern matching\n",
    "import matplotlib.pyplot as plt    # Data visualization libary\n",
    "import matplotlib.image as mpimg   # Image processing library\n",
    "# Visualizations will be shown in the notebook\n",
    "%matplotlib inline                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_points(do_plot=False, do_file=False):\n",
    "    # Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(8,5,0)\n",
    "    objp = np.zeros((6*9, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images\n",
    "    objpoints = []                     # 3D points in real world space\n",
    "    imgpoints = []                     # 2D points in image plain\n",
    "\n",
    "    # List of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "    print('Num of calibration images: {0}'.format(len(images)))\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for img_id, fname in enumerate(images): \n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Grayscale\n",
    "        \n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
    "        # If found - add object points, add image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(img, (9, 6), corners, ret)\n",
    "            # Draw the plot\n",
    "            if do_plot:\n",
    "                plt.imshow(img)\n",
    "                plt.show()\n",
    "            # Save to the file\n",
    "            if do_file:\n",
    "                write_name = 'corners_' + str(img_id) + '.jpg' # Name to give image\n",
    "                cv2.imwrite(write_name, img) # Write and save file locally\n",
    "    return objpoints, imgpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickle_dump(mtx, dist):\n",
    "    # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    pickle.dump(dist_pickle, open('wide_dist_pickle.p', 'wb'))\n",
    "    \n",
    "def pickle_load():\n",
    "    # Getting back the camera calibration result:\n",
    "    with open('wide_dist_pickle.p', 'rb') as f:\n",
    "        dist_pickle = pickle.load(f)\n",
    "        return dist_pickle['mtx'], dist_pickle['dist']\n",
    "    \n",
    "def calibrate_camera(img):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    # Do camera calibration given object points and image points\n",
    "    objpoints, imgpoints = calibration_points(do_plot=False, do_file=False)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    # Save the camera calibration result\n",
    "    pickle_dump(mtx, dist)\n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For universal plotting of results\n",
    "def plot_row2(img1, img2, label_1, label_2, graysc=True):\n",
    "    # Plot the result (1 row with 2 images)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    f.tight_layout()\n",
    "    if graysc:\n",
    "        ax1.imshow(img1, cmap='gray')\n",
    "    else:\n",
    "        ax1.imshow(img1)\n",
    "    ax1.set_title(label_1, fontsize=16)\n",
    "    ax2.imshow(img2, cmap='gray')\n",
    "    ax2.set_title(label_2, fontsize=16)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Sobel (Calculate directional gradient and apply gradient threshold)\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Convert to HLS and take S channel\n",
    "    img_trans = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    img_trans = img_trans[:,:,2]\n",
    "    # Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(img_trans, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(img_trans, cv2.CV_64F, 0, 1, ksize=sobel_kernel) \n",
    "    # Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "    # Create a mask of 1's where the scaled gradient magnitude \n",
    "    # is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    # Return mask as binary_output image\n",
    "    return binary_output\n",
    "\n",
    "# Return the magnitude of the gradient for a given sobel kernel \n",
    "# size and threshold values in both x and y\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Convert to HLS and take S channel\n",
    "    img_trans = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    img_trans = img_trans[:,:,2]\n",
    "    # Take the gradient in x and y separately\n",
    "    sobel_x = cv2.Sobel(img_trans, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(img_trans, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8)\n",
    "    # Create a binary mask where mag thresholds are met\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    # Return mask as binary_output image\n",
    "    return binary_output\n",
    "\n",
    "# Calculate gradient direction and apply threshold\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Convert to HLS and take S channel\n",
    "    img_trans = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    img_trans = img_trans[:,:,2]\n",
    "    # Take the gradient in x and y separately\n",
    "    sobel_x = cv2.Sobel(img_trans, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(img_trans, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the x and y gradients\n",
    "    abs_sobel_x = np.absolute(sobel_x)\n",
    "    abs_sobel_y = np.absolute(sobel_y)\n",
    "    # Use np.arctan2(abs_sobel_y, abs_sobimg_transel_x) to calculate the direction of the gradient\n",
    "    absgraddir = np.arctan2(abs_sobel_y, abs_sobel_x)\n",
    "    # Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "    # Return this mask as binary_output image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sobel_thresholds(img, do_plot=False):\n",
    "    # Gaussian Blur\n",
    "    kernel_size = 5\n",
    "    img = cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "    # Sobel kernel size (choose a larger odd number to smooth gradient measurements)\n",
    "    ksize = 7\n",
    "    # Apply Sobel on x-axis\n",
    "    grad_x_binary = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(10, 255))\n",
    "    # Apply Sobel on y-axis\n",
    "    grad_y_binary = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=(60, 255))\n",
    "    # Apply Sobel x and y, compute the magnitude of the gradient and apply a threshold\n",
    "    mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(40, 255))\n",
    "    # Apply Sobel x and y, computes the direction of the gradient and apply a threshold\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=ksize, thresh=(0.65, 1.05))\n",
    "    \n",
    "    # Combine the thresholds\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((grad_x_binary == 1) & (grad_y_binary == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    \n",
    "    if do_plot:\n",
    "        plot_row2(image, grad_x_binary,      'Original Image (Undistorted)', 'Sobel on x-axis')\n",
    "        plot_row2(grad_y_binary, mag_binary, 'Sobel on y-axis', 'Thresholded Magnitude')\n",
    "        plot_row2(dir_binary, combined,      'Direction of gradient', 'Combined Thresholds')\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_channel_threshold(img, thresh=(0, 255), do_plot=False):\n",
    "    # Convert to HLS color space and separate the S channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    # Extract S channel\n",
    "    s_channel = hls[:,:,2]\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    \n",
    "    if do_plot:\n",
    "        plot_row2(image, s_binary, 'Original Image (Undistorted)', 'HLS(S-channel) threshold')\n",
    "    return s_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies an image mask\n",
    "# Only keeps the region of the image defined by the polygon formed from `vertices`.\n",
    "# The rest of the image is set to black.\n",
    "def region_of_interest(img, vertices):\n",
    "    # Defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "    ignore_mask_color = 255\n",
    "    # Fill pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    # Return the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def perspective_transform(img, inv=False):\n",
    "    # Define 4 source points\n",
    "    src = np.float32([[180, img.shape[0]], [575, 460], \n",
    "                      [705, 460], [1150, img.shape[0]]])\n",
    "    # Define 4 destination points\n",
    "    dst = np.float32([[320, img.shape[0]], [320, 0], \n",
    "                      [960, 0], [960, img.shape[0]]])\n",
    "    # Use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "    if inv == False:\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "    else:\n",
    "        M = cv2.getPerspectiveTransform(dst, src)\n",
    "    # Use cv2.warpPerspective() to warp image to a top-down view\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # If line detected\n",
    "        self.detected = False  \n",
    "        # The x values of the last n fits\n",
    "        self.recent_xfitted = collections.deque(12*[0.0, 0.0, 0.0], 12)\n",
    "        # Mean x values of best fit line\n",
    "        self.bestx = None\n",
    "        # Mean polynomial coefficients \n",
    "        self.best_fit = None  \n",
    "        # Polynomial coefficients for fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        # Curvature radius of line in meters\n",
    "        self.radius_of_curvature = None \n",
    "        # Meters from center of the line\n",
    "        self.line_base_pos = None\n",
    "        # Difference in old and new fit coefficients \n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        # The x values for detected line pixels\n",
    "        self.allx = None\n",
    "        # The y values for detected line pixels\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMERA CALIBRATION AND IMAGE UNDISTORTION\n",
    "# DON'T HAVE TO USE CAMERA CALIBRATION???\n",
    "def get_undist():\n",
    "    # Test undistortion on the image\n",
    "    img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "    # Load calibration data from pickle\n",
    "    mtx, dist = pickle_load()\n",
    "    # Undistort image\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLOR / GRADIENT THRESHOLD\n",
    "mtx, dist = get_undist()\n",
    "def threshold(image):\n",
    "    # Undistort image\n",
    "    undist_image = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    # Perform Sobel operations and combine thresholds\n",
    "    combine_sobel = combine_sobel_thresholds(undist_image, do_plot=False)\n",
    "    # Threshold color channel\n",
    "    color_thresh = color_channel_threshold(undist_image, thresh=(160, 255), do_plot=False)\n",
    "    # Combine color and gradient thresholds\n",
    "    combined_binary = np.zeros_like(color_thresh)\n",
    "    combined_binary[(combine_sobel == 1) | (color_thresh == 1)] = 1\n",
    "    return combined_binary, undist_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERSPECTIVE TRANSFORM\n",
    "def warp(thresholded):\n",
    "    # Run perspective transform function\n",
    "    warped_img = perspective_transform(thresholded)\n",
    "    \n",
    "    # Define image mask (polygon of interest)\n",
    "    imshape = warped_img.shape\n",
    "    vertices = np.array([[(200, imshape[0]), (200, 0), (imshape[1] - 200, 0), \n",
    "                      (imshape[1]-200, imshape[0])]], dtype=np.int32)\n",
    "    masked_img = region_of_interest(warped_img, vertices)\n",
    "    #plot_row2(warped_img, masked_img, 'Warped image', 'Warped image with mask')\n",
    "    return masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
